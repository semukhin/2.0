

# **LawGPT 2.0: Архитектурный план для производственной многоагентной системы юридического анализа**

## **Исполнительное резюме и стратегические рекомендации**

### **Обзор**

Данный документ представляет собой исчерпывающий архитектурный план для LawGPT 2.0 — платформы юридического искусственного интеллекта нового поколения. В нем излагается стратегия перехода от текущей системы к сложной, аудируемой и масштабируемой многоагентной архитектуре, разработанной для удовлетворения строгих требований юридической профессии.

### **Ключевые стратегические решения**

* **Миграция технологического стека:** Настоящим документом формально рекомендуется и подробно описывается миграция с существующего стека Node.js/TypeScript на экосистему **Python 3.11+** с использованием **FastAPI** в качестве веб\-фреймворка и **LangChain/LangGraph** для оркестрации ИИ. Это решение обусловлено несравненной зрелостью, скоростью разработки и широтой экосистемы Python в области ИИ, что является критически важным для долгосрочных инноваций и привлечения талантов.1  
* **Унифицированный бэкенд данных и поисковый движок:** Все данные приложения, включая реляционные данные, историю чатов и векторные эмбеддинги, будут консолидированы в едином экземпляре **PostgreSQL (v15+)** с расширением pgvector. Этот шаг упрощает технологический стек, обеспечивает транзакционную целостность и создает мощную основу для продвинутого гибридного поиска.  
* **Оркестрация с помощью LangGraph:** Когнитивное ядро системы будет построено с использованием **LangGraph**. Его явная, основанная на конечном автомате парадигма графов обеспечивает необходимый уровень контроля, детерминизма и аудируемости, требуемый для юридического анализа, что является строгим и необходимым отличием от менее предсказуемых, эмерджентных агентных фреймворков.3

### **Ключевые архитектурные инновации**

* **Иерархическая команда агентов:** Команда специализированных ИИ-агентов под управлением CoordinatorAgent, оптимизирующего затраты, будет декомпозировать сложные юридические запросы на управляемые подзадачи, обеспечивая экспертизу на основе ролей и эффективное распределение ресурсов.  
* **Продвинутая расширенная генерация с извлечением данных (RAG):** Система выйдет за рамки простого семантического поиска за счет реализации движка **гибридного поиска** с использованием Reciprocal Rank Fusion (RRF) и интеграции принципов **GraphRAG** и **саморефлексивного RAG** для кардинального повышения точности извлечения и контекстного анализа.  
* **Человек-в-цикле (Human-in-the-Loop, HITL) как неотъемлемая часть архитектуры:** Критически важные этапы анализа будут спроектированы с явными точками прерывания (interrupt), что позволит осуществлять обязательную проверку и утверждение человеком, обеспечивая надежность и доказуемость результатов системы.

### **Влияние на бизнес и операционную деятельность**

Данная архитектура предназначена для обеспечения качественного скачка в возможностях, предоставляя более точный, детализированный и прозрачный юридический анализ. В операционном плане она делает акцент на наблюдаемости (через LangSmith), безопасности и четком пути для будущего масштабирования.

---

## **Раздел 1: Фундаментальная архитектура: Оркестрация и персистентность данных**

В этом разделе излагаются два основополагающих столпа новой архитектуры: фреймворк для оркестрации ИИ и унифицированный бэкенд данных. Здесь обосновываются стратегические технологические решения, которые лягут в основу всей системы.

### **1.1. Оркестрационный движок: Почему LangGraph является безальтернативным выбором для юридического ИИ**

#### **Основное обоснование**

Юридические приложения требуют абсолютной ясности, аудируемости и детерминированного контроля над процессом рассуждений. Необходимо иметь возможность отследить каждый шаг анализа. Архитектура LangGraph, которая моделирует рабочие процессы как явный, состоянийный граф (направленный ациклический граф с циклами), фундаментально соответствует этому требованию.4 Этот подход «прозрачного ящика» является непреложным преимуществом по сравнению с «черным ящиком» или эмерджентными разговорными моделями.5

#### **Сравнительный анализ**

* **LangGraph vs. AutoGen:** Сильная сторона AutoGen заключается в создании систем, где агенты взаимодействуют в рамках «беседы» для совместного решения сложных задач.7 Однако это эмерджентное поведение вносит уровень непредсказуемости, который является неприемлемым риском в юридической области, где требуется строгая воспроизводимость.5 Явная структура узлов и ребер в LangGraph обеспечивает превосходный контроль и возможности для отладки.4  
* **LangGraph vs. LlamaIndex:** LlamaIndex — это мощный, ориентированный на данные фреймворк, оптимизированный для задач RAG, но его агентные «Workflows» в основном событийно-ориентированы.5 В сложных сценариях с ветвлениями и циклами, характерных для юридического анализа, такая парадигма может затенять общую логику потока состояний по сравнению с визуально и программно представимым конечным автоматом LangGraph.10

Выбор фреймворка для оркестрации — это не просто техническая деталь, а философское решение. Философия AutoGen поощряет эмергентный интеллект, в то время как философия LangGraph отдает приоритет явному, контролируемому и аудируемому процессу. Для юридического продукта, где каждый вывод должен быть объясним и защищаем, последний подход является единственно верным. Это решение определяет весь наш подход к проектированию агентов: мы будем создавать не «разговаривающих» агентов, а функциональные узлы в детерминированном графе, каждый из которых имеет четкую, тестируемую зону ответственности. Такой подход значительно упрощает отладку и валидацию, что является огромным операционным преимуществом.

#### **Ключевые концепции LangGraph для LawGPT**

* **StateGraph:** Основной объект, определяющий структуру рабочих процессов наших агентов. Каждый узел будет представлять собой агента или инструмент, а каждое ребро — определенный переход.2  
* **State:** Типизированный словарь (в Python — Pydantic-модель), который служит общим контекстом или «рюкзаком с информацией», передаваемым между узлами. Это обеспечивает согласованность данных и безопасность типов на протяжении всего рабочего процесса.2  
* **Checkpointers:** Встроенный механизм для сохранения State во внешнюю базу данных (например, Redis, PostgreSQL). Это критически важно для реализации длительных задач, отказоустойчивости (возобновление после сбоя) и обеспечения работы Human-in-the-Loop.3

### **1.2. Унифицированный бэкенд данных: Консолидация на PostgreSQL**

#### **Стратегическое обоснование**

Современная парадигма использования отдельных баз данных для реляционных данных, векторного поиска и состояния приложения вносит значительную операционную сложность, проблемы с синхронизацией данных и потенциальные риски для их целостности. Консолидация на PostgreSQL (v15+) с расширением pgvector создает единый, транзакционно-согласованный источник истины для всего приложения.13 Это упрощает резервное копирование, разработку и управление данными.

#### **Анализ производительности pgvector (индекс HNSW)**

* Для наборов данных объемом до 10-50 миллионов векторов pgvector с хорошо настроенным индексом HNSW обеспечивает превосходную производительность (задержка менее 100 мс при полноте \>99%), которая конкурентоспособна со специализированными базами данных, особенно с учетом его превосходной параллельной пропускной способности.14  
* Основной компромисс заключается в его производительности на очень больших наборах данных, не помещающихся в память (\>100 млн векторов). Графовая природа HNSW может приводить к дорогостоящему случайному вводу-выводу, когда индекс не помещается в память, что вызывает значительное ухудшение задержки (в одном из тестов \>4 с) по сравнению со специализированными решениями, такими как ScaNN от Google или выделенные векторные БД.15  
* Недавние улучшения в pgvector (v0.8.0+) ввели такие функции, как iterative\_scan, для повышения полноты при фильтрованных запросах, устраняя ключевую историческую слабость.16

Выбор pgvector является стратегическим решением, которое в среднесрочной перспективе отдает приоритет архитектурной простоте и целостности данных, признавая при этом потенциальную проблему масштабирования в будущем. Это разумный инженерный компромисс. Игнорирование этого потенциального «обрыва производительности» было бы безответственным архитектурным планированием. Признание этого факта позволяет нам заранее к нему подготовиться. План реализации (Раздел 5\) должен включать «Стратегию масштабирования векторов». Это будет определять конкретные дашборды для мониторинга (например, в Grafana) для отслеживания задержки запросов (p95, p99) и размера индекса. Будет предварительно определен порог (например, задержка p99, постоянно превышающая 500 мс), который инициирует формальный пересмотр для миграции векторной нагрузки на специализированное, масштабируемое решение, такое как Qdrant 17 или Milvus 18, которые предназначены для такого масштаба. Это превращает будущий риск в спланированную, измеримую эволюцию.

### **Таблица 1: Рекомендации по фундаментальному технологическому стеку**

| Компонент | Рекомендуемая технология | Обоснование | Ключевая поддержка в исследованиях |
| :---- | :---- | :---- | :---- |
| **Оркестрация ИИ** | LangGraph (Python) | Обеспечивает необходимый контроль, аудируемость и сохранение состояния для юридических рабочих процессов с высокими ставками. | 3 |
| **Веб-фреймворк** | FastAPI | Высокопроизводительный, с нативной поддержкой асинхронности, идеально интегрируется с экосистемой Python для науки о данных/ИИ. | 19 |
| **База данных** | PostgreSQL v15+ | Унифицированное, транзакционно-согласованное хранилище для всех данных приложения. |  |
| **Векторный поиск** | pgvector (индекс HNSW) | Отличная производительность для наборов данных среднего размера при сохранении архитектурной простоты. Имеется план масштабирования для \>100 млн векторов. | 14 |
| **Наблюдаемость** | LangSmith | Незаменимый инструмент для трассировки, отладки и оценки сложных многоагентных взаимодействий. | 9 |

---

## **Раздел 2: Когнитивная архитектура: Многоагентная система юридического анализа**

В этом разделе подробно описывается «мозг» LawGPT, определяя агентов, их модели сотрудничества и то, как их коллективный интеллект будет оркестрован.

### **2.1. Состояние агента: Централизованный, типизированный «рюкзак» для рассуждений**

#### **Определение состояния**

AgentState является самой важной структурой данных в графе. Он будет определен как TypedDict в Pydantic для обеспечения строгой проверки типов и поддержки в IDE. Этот объект состояния является изменяемым и передается между всеми узлами, служа «единым источником истины» для конкретной задачи анализа.2

#### **Схема AgentState на Pydantic**

Python

from typing import List, Dict, Any, Annotated  
from typing\_extensions import TypedDict  
from langchain\_core.documents import Document  
from langgraph.graph.message import add\_messages

class AgentState(TypedDict):  
    original\_query: str  
    search\_query: str  
    retrieved_documents: List[Document]  
    analyzed\_facts: Dict\[str, Any\]  
    synthesized\_argument: str  
    final\_response: str  
    messages: Annotated\[list, add\_messages\]  
    \#... другие промежуточные состояния

#### **Двухуровневая архитектура памяти**

Единый механизм персистентности неэффективен как для производительности, так и для долговечности. Будет реализована двухуровневая стратегия:

* **Краткосрочная/сессионная память (горячее хранилище):** checkpointer в LangGraph будет настроен на использование **Redis** (RedisSaver). Redis обеспечивает низкую задержку и высокую пропускную способность, необходимые для сохранения AgentState после *каждого* шага агента во время активной сессии пользователя. Использование дисковой базы данных, такой как Postgres, для этой цели создало бы узкое место в производительности при высокой нагрузке.23  
* **Долгосрочная/архивная память (холодное хранилище):** После успешного завершения выполнения графа окончательный массив messages из AgentState будет сохранен в основной базе данных **PostgreSQL** с помощью класса PostgresChatMessageHistory из LangChain. Это соответствует нашей стратегии консолидации данных и делает историю бесед доступной для аналитики и дообучения наряду с другими данными приложения.24

Такой гибридный подход является зрелым, ориентированным на производство паттерном, который решает конфликтующие задачи производительности и консолидации данных. Он разделяет «горячее» хранилище активных состояний (Redis) и «холодное» архивное хранилище (Postgres), обеспечивая отказоустойчивость системы при пиковых нагрузках, при этом сохраняя все долгосрочные данные в единой, согласованной базе.

### **2.2. Иерархическая команда агентов: Роли, промпты и инструменты**

#### **Архитектура**

Будет принята архитектура **иерархического супервизора**.25 Центральный

CoordinatorAgent будет действовать как супервизор, декомпозируя запрос пользователя и делегируя подзадачи команде специализированных рабочих агентов. Это более структурированный и контролируемый подход, чем плоская, разговорная сеть агентов.

#### **Спецификации агентов**

* **CoordinatorAgent (Супервизор/Маршрутизатор):**  
  * **Ответственность:** Точка входа. Анализирует запрос пользователя и историю чата. Его основная роль — **декомпозировать задачу** и **сформулировать план выполнения** в виде структурированного JSON-объекта. Он также будет действовать как **оптимизирующий затраты маршрутизатор LLM**.  
  * **Инжиниринг промптов:** Промпт будет иметь решающее значение. Ему будет поручено анализировать сложность и намерение запроса. Для простых задач (например, «Что такое деликт?») он может направить запрос напрямую к WebSearchAgent, используя дешевую и быструю модель, такую как Gemini 1.5 Flash. Для сложных задач («Подготовьте ходатайство об отклонении иска на основе этих фактов и прецедентов») он сгенерирует многоэтапный план, включающий нескольких специализированных агентов, и будет использовать мощную модель для рассуждений, такую как GPT-4o или Claude 3.5 Sonnet.28  
  * **Инструменты:** В основном использует свою LLM для рассуждений. У него не будет внешних инструментов, но его вывод (план) будет использоваться условными ребрами графа для маршрутизации к другим агентам.  
* **LegalSearchAgent (Исследователь):**  
  * **Ответственность:** Выполняет расширенный поиск во внутренней базе знаний.  
  * **Инструменты:** Единый мощный инструмент hybrid\_search, который инкапсулирует логику поиска на основе RRF, определенную в Разделе 3\.  
* **DocumentAnalysisAgent (Извлекатель):**  
  * **Ответственность:** Обрабатывает документы, возвращенные LegalSearchAgent. Использует вызов функций LLM для извлечения структурированных фактов, аргументов и цитат в поле analyzed\_facts объекта AgentState. Этот структурированный вывод жизненно важен для следующего шага.  
  * **Инструменты:** LLM с возможностью вызова функций/инструментов (например, API вызова функций Gemini 23).  
* **CaseLawSynthesisAgent (Синтезатор/Аналитик):**  
  * **Ответственность:** Основной механизм рассуждений. Он принимает структурированные analyzed\_facts из нескольких документов и синтезирует их в связный аргумент, выявляя закономерности, противоречия и подтверждающие доказательства.  
  * **Инструменты:** Мощная LLM для рассуждений (например, GPT-4o). Внешние инструменты отсутствуют.  
* **DocumentDrafterAgent (Составитель):**  
  * **Ответственность:** Принимает synthesized\_argument и составляет формальный юридический документ (например, меморандум, ходатайство, пункт договора).  
  * **Инструменты:** LLM для генерации длинных текстов.  
* **ResponseFinalizerAgent (Редактор):**  
  * **Ответственность:** Форматирует окончательный вывод для пользователя, добавляя необходимые цитаты, оговорки и обеспечивая профессиональный тон.  
  * **Инструменты:** LLM для форматирования текста.

CoordinatorAgent — это не просто маршрутизатор; это стратегический контрольный пункт как для **стоимости, так и для качества**. Сделав его «планировщиком, осведомленным о затратах», можно построить систему, которая динамически выделяет дорогостоящие ресурсы (мощные LLM) только при необходимости. Вместо создания отдельного агента-маршрутизатора, эта логика встраивается непосредственно в промпт CoordinatorAgent. Промпт будет явно просить LLM оценить сложность запроса и выбрать соответствующую модель/путь агента. Этот паттерн проектирования делает систему экономически жизнеспособной, предотвращая использование дорогостоящей модели, такой как GPT-4o, для ответа на простой фактический вопрос, что потенциально снижает операционные расходы на порядок для значительной части запросов пользователей.

### **2.3. Реализация на LangGraph: Определение потока юридического анализа**

#### **Построение графа**

Для объединения агентов будет использоваться StateGraph из LangGraph.

* **Узлы:** Каждая функция агента (например, run\_legal\_search\_agent, run\_synthesis\_agent) становится узлом в графе. Также будет создан ToolNode для выполнения инструмента hybrid\_search.32  
* **Точка входа:** Точкой входа в граф будет CoordinatorAgent.  
* **Условные ребра:** Наиболее важная часть оркестровки. После выполнения CoordinatorAgent условное ребро будет считывать plan из AgentState и направлять выполнение к первому агенту, указанному в плане. Последующие условные ребра будут управлять потоком между агентами, циклически проходя через анализ документов или переходя к синтезу.  
* **Обработка ошибок:** Будут использованы встроенные возможности LangGraph для обеспечения отказоустойчивости. Для временных ошибок (например, таймауты API) будет использоваться метод .with\_retry() на конкретном узле.33 Для более сложных сбоев (например, сбой валидации вызова инструмента) условное ребро может направить состояние на выделенный  
  error\_handling\_node, который может попытаться самоскорректироваться или пометить проблему для проверки человеком.34

#### **Визуализация архитектуры**

Следующая диаграмма в формате Mermaid.js визуализирует высокоуровневый поток управления.

Фрагмент кода

graph TD  
    A\[Начало: Запрос пользователя\] \--\> B(CoordinatorAgent);  
    B \--\> C{Маршрутизация по плану};  
    C \-- Юридический поиск \--\> D(LegalSearchAgent);  
    D \--\> E{Документы найдены?};  
    E \-- Да \--\> F(DocumentAnalysisAgent);  
    E \-- Нет \--\> G\[Конец: Результаты не найдены\];  
    F \--\> H(CaseLawSynthesisAgent);  
    H \--\> I{Требуется проверка человеком?};  
    I \-- Да \--\> J(HITL: Пауза для проверки);  
    I \-- Нет \--\> K(DocumentDrafterAgent);  
    J \-- Утверждено \--\> K;  
    J \-- Отклонено \--\> L\[Конец: Отклонено\];  
    K \--\> M(ResponseFinalizerAgent);  
    M \--\> N\[Конец: Финальный ответ\];

### **Таблица 2: Команда многоагентной системы LawGPT: Роли, промпты, инструменты и ввод/вывод состояния**

| Имя агента | Основная ответственность | Ключевые инструкции в промпте | Инструменты | Входные поля состояния | Выходные поля состояния |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **CoordinatorAgent** | Декомпозиция задачи и оптимизация затрат. | Анализировать сложность запроса. Создать JSON-план. Выбирать модель (дешевую/дорогую) в зависимости от сложности. | LLM (рассуждение) | original\_query, messages | plan, search\_query |
| **LegalSearchAgent** | Выполнение гибридного поиска в базе знаний. | Переформулировать запрос для оптимального поиска. Выполнить поиск. | hybrid\_search | search\_query | retrieved\_documents |
| **DocumentAnalysisAgent** | Извлечение структурированных фактов из документов. | Итерировать по документам. Извлечь факты, аргументы, цитаты. | LLM (вызов функций) | retrieved\_documents | analyzed\_facts |
| **CaseLawSynthesisAgent** | Анализ и синтез извлеченных фактов в единый аргумент. | Найти закономерности, противоречия, подтверждения. Сформировать связный аргумент. | LLM (рассуждение) | analyzed\_facts | synthesized\_argument |
| **DocumentDrafterAgent** | Составление проектов юридических документов. | На основе аргумента составить формальный документ (меморандум, ходатайство). | LLM (генерация текста) | synthesized\_argument | draft\_document |
| **ResponseFinalizerAgent** | Форматирование финального ответа для пользователя. | Отформатировать ответ, добавить цитаты, оговорки. Обеспечить профессиональный тон. | LLM (форматирование) | draft\_document | final\_response |

---

## **Раздел 3: Унифицированный движок данных: Реализация продвинутого поиска и знаний**

Этот раздел представляет собой подробный инженерный план по созданию бэкенда данных, переходя от высокоуровневой стратегии к предписывающим SQL-запросам и коду.

### **3.1. Схема базы данных и стратегия индексирования**

#### **Таблица knowledge\_base**

Это будет центральная таблица для всех юридических документов. Схема, предложенная в Спецификации 1, является превосходной и будет принята с небольшими улучшениями.

SQL

CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE knowledge\_base (  
    id BIGSERIAL PRIMARY KEY,  
    source\_type VARCHAR(100) NOT NULL, \-- например, 'court\_case', 'statute', 'contract'  
    content TEXT NOT NULL,  
    metadata JSONB, \-- Для юрисдикции, дат, сторон и извлеченных сущностей графа  
    embedding VECTOR(1536) NOT NULL, \-- Соответствует text-embedding-3-large  
    content\_tsv TSVECTOR,  
    created\_at TIMESTAMPTZ DEFAULT CURRENT\_TIMESTAMP  
);

#### **Стратегия индексирования**

* **Индекс для полнотекстового поиска (FTS):** CREATE INDEX idx\_knowledge\_base\_tsv ON knowledge\_base USING GIN(content\_tsv); 36  
* **Индекс для векторного поиска:** CREATE INDEX idx\_knowledge\_base\_embedding ON knowledge\_base USING HNSW (embedding vector\_cosine\_ops); HNSW выбран за его превосходный баланс скорости и полноты для поиска по примерному ближайшему соседству в памяти.37 Параметры (  
  m, ef\_construction) будут настроены на основе тестов производительности с реальным юридическим корпусом.  
* **Индекс для метаданных:** CREATE INDEX idx\_knowledge\_base\_metadata ON knowledge\_base USING GIN(metadata); Это критически важно для эффективной фильтрации на основе структурированных данных в столбце JSONB.

#### **Автоматическое обновление tsvector**

Триггер из Спецификации 1 будет реализован для обеспечения постоянной синхронизации индекса FTS с содержимым content.39

### **3.2. Реализация продвинутого гибридного поиска с Reciprocal Rank Fusion (RRF)**

#### **Выбор алгоритма**

RRF является предпочтительным методом для слияния ранжированных списков из различных поисковых модальностей (лексический FTS и семантический векторный поиск). Он устойчив к различным шкалам оценок, генерируемых ts\_rank и косинусным расстоянием, и менее чувствителен к выбросам, чем методы нормализации оценок, такие как min-max.40 Константа

k (обычно 60\) действует как сглаживающий фактор, чтобы предотвратить доминирование в конечном результате документов с высоким рангом в одном из списков.41

#### **Стратегия реализации (Python/FastAPI)**

1. Инструмент hybrid\_search будет асинхронной (async) функцией.  
2. Он будет использовать asyncio.gather для параллельного выполнения двух SQL-запросов к PostgreSQL: один для FTS и один для векторного поиска.  
3. Каждый запрос вернет список идентификаторов документов и их рангов.  
4. Функция на уровне приложения в Python реализует алгоритм RRF, принимая два ранжированных списка, вычисляя оценку RRF для каждого уникального документа и возвращая итоговый, переранжированный список идентификаторов документов.  
5. Финальный запрос извлечет полное содержимое документов для топ-N переранжированных идентификаторов.

Эта стратегия слияния на уровне приложения, хотя и немного сложнее, чем функция в базе данных, обеспечивает критическую гибкость и разделяет поисковые модальности. Это позволяет независимо тестировать, версионировать и изменять каждый компонент (FTS-запрос, векторный запрос, алгоритм слияния). Например, если в будущем потребуется добавить третью модальность поиска (например, поиск по ключевым словам в метаданных), изменить код на Python на уровне приложения будет гораздо проще, чем переписывать сложную SQL-функцию. Эта модульность является ключевым принципом надежного программного обеспечения.

### **3.3. Прагматичный GraphRAG: Использование PostgreSQL для структурированных знаний**

#### **Задача**

Полноценный GraphRAG часто требует выделенной графовой базы данных, такой как Neo4j 42, что нарушило бы наш принцип единого бэкенда данных.

#### **Прагматичное решение**

Принципы GraphRAG могут быть реализованы в рамках PostgreSQL. DocumentAnalysisAgent будет извлекать сущности (например, судей, компании, правовые принципы) и их отношения. Эти структурированные данные будут храниться в столбце metadata типа JSONB таблицы knowledge\_base.

#### **Пример структуры metadata**

JSON

{  
  "case\_number": "CV-2024-123",  
  "jurisdiction": "California",  
  "entities":,  
  "relationships":  
}

#### **Запросы к «графу»**

LegalSearchAgent может выполнять «графоподобные» обходы, создавая SQL-запросы, которые фильтруют эти данные JSONB. Например, чтобы найти документы, связанные с «Acme Corp», он может выполнить векторный поиск, отфильтрованный с помощью WHERE metadata @\> '{"entities": \[{"name": "Acme Corp"}\]}'. Это сочетает семантический поиск со структурированной, графоподобной фильтрацией, значительно повышая точность извлечения для именованных сущностей.42

Этот паттерн «Граф-на-JSONB» является мощным, прагматичным компромиссом, который предоставляет многие преимущества GraphRAG (структурированное извлечение) без операционных накладных расходов на управление отдельной графовой базой данных. Он обеспечивает значительное улучшение по сравнению с базовым векторным поиском и соответствует нашим основным архитектурным принципам. Он также предоставляет структурированный набор данных, который можно будет использовать для заполнения настоящей графовой базы данных в будущем, если возникнет такая необходимость.

---

## **Раздел 4: Расширенные возможности: Самокоррекция и Human-in-the-Loop (HITL)**

В этом разделе подробно описывается, как мы будем встраивать интеллект и безопасность в агентный рабочий процесс, переходя от простого выполнения к рефлексии и человеческому надзору.

### **4.1. Реализация цикла саморефлексивного RAG**

#### **Концепция**

Стандартный RAG может потерпеть неудачу, если первоначальное извлечение данных будет некачественным («мусор на входе — мусор на выходе»). Цикл саморефлексии добавляет этап контроля качества. После извлечения агент оценивает релевантность возвращенных документов, прежде чем продолжить.44

#### **Реализация в LangGraph**

1. После узла LegalSearchAgent будет добавлен новый узел под названием EvaluateRetrievalNode.  
2. Этот узел будет использовать LLM (достаточно дешевой и быстрой модели) с промптом вроде: «Учитывая запрос \[user\_query\] и следующие резюме документов \[summaries\], релевантны ли эти документы для ответа на запрос? Ответьте 'Relevant' или 'Irrelevant'».  
3. Условное ребро после EvaluateRetrievalNode проверит ответ LLM.  
   * Если «Relevant», граф перейдет к DocumentAnalysisAgent.  
   * Если «Irrelevant», граф направит поток к RefineQueryNode. Этот узел возьмет исходный запрос и обратную связь и использует LLM для генерации нового, более конкретного поискового запроса. Затем состояние будет направлено обратно к LegalSearchAgent для повторной попытки. В состояние будет добавлен счетчик для предотвращения бесконечных циклов.

Этот цикл самокоррекции делает процесс RAG более устойчивым к неоднозначным запросам пользователей и несовершенному извлечению. Он имитирует то, как человек-исследователь уточнил бы свои поисковые запросы, если бы первоначальные результаты оказались бесполезными. Циклическая природа LangGraph идеально подходит для реализации этого паттерна.44 Это значительно повышает надежность и воспринимаемый интеллект системы, снижая количество неудачных сессий и повышая доверие пользователей.

### **4.2. Проектирование для человеческого надзора: Паттерн валидации HITL**

#### **Концепция**

Для юридического приложения некоторые результаты (например, окончательный юридический аргумент, проект контракта) *должны* быть проверены человеком-профессионалом перед финализацией. Функция interrupt в LangGraph предназначена именно для этой цели.3

#### **Реализация в LangGraph**

1. После CaseLawSynthesisAgent или DocumentDrafterAgent будет добавлен узел HumanReviewNode.  
2. Функция этого узла вызовет interrupt(), передавая контент для проверки на фронтенд.46  
3. Выполнение графа приостановится, а его состояние будет сохранено с помощью чекпоинтера Redis.  
4. Фронтенд отобразит контент и предоставит кнопки «Утвердить» и «Отклонить/Редактировать».  
5. Когда пользователь нажмет кнопку, фронтенд сделает API-вызов к бэкенду FastAPI.  
6. Бэкенд возобновит выполнение графа, вызвав метод update или stream скомпилированного графа с Command(resume=...), передавая решение человека обратно в граф.46  
7. Условное ребро после HumanReviewNode направит поток. Если «Утверждено», он перейдет к ResponseFinalizerAgent. Если «Отклонено», он может вернуться к агенту синтеза с обратной связью от человека для повторной разработки.

HITL — это не просто функция, а основной архитектурный компонент, который обеспечивает юридическое соответствие и укрепляет доверие. Интегрируя его непосредственно в агентный рабочий процесс, мы делаем его обязательным, аудируемым шагом. Этот механизм полагается на систему чекпоинтов для приостановки и возобновления состояния, что еще раз подчеркивает важность двухуровневой архитектуры памяти из Раздела 2\. Такая конструкция обеспечивает защищаемый аудиторский след. Мы можем регистрировать каждое взаимодействие HITL: кто его проверял, когда и какие действия предпринял. Это бесценно для соблюдения нормативных требований и демонстрации надежности системы клиентам и регуляторам. Это превращает ИИ из «черного ящика» в прозрачного «второго пилота» для юристов.

---

## **Раздел 5: Внедрение в производство, безопасность и эксплуатация**

В этом разделе подробно описываются практические шаги по развертыванию, мониторингу и обеспечению безопасности системы LawGPT 2.0.

### **5.1. Развертывание и конвейер CI/CD на Google Cloud Platform (GCP)**

#### **Контейнеризация и развертывание**

* **Контейнеризация:** Приложение FastAPI будет контейнеризировано с использованием многоступенчатого Dockerfile. Это обеспечивает согласованную, воспроизводимую среду выполнения и оптимизирует размер конечного образа.48  
* **Цель развертывания:** **Google Cloud Run** является идеальной платформой для развертывания. Это бессерверная платформа, которая автоматически масштабируется в зависимости от трафика (включая масштабирование до нуля, что очень экономично) и нативно поддерживает потоковую передачу ответов, необходимую для нашего приложения.20

#### **Конвейер CI/CD**

Будет настроен конвейер непрерывной интеграции и непрерывного развертывания (CI/CD) с использованием **GitHub Actions**.

* **При Pull Request:** Автоматический запуск линтеров, а также модульных и интеграционных тестов.  
* **При слиянии в main:**  
  1. Запуск **Google Cloud Build** для сборки Docker-образа.49  
  2. Отправка помеченного тегом образа в **Google Artifact Registry**.50  
  3. Развертывание нового образа в Cloud Run.49

Полностью автоматизированный конвейер CI/CD является критически важной инвестицией, которая значительно увеличивает скорость разработки и снижает риск при развертывании. Ручные развертывания медленны, подвержены ошибкам и не масштабируются.1 Сочетание GitHub Actions и Cloud Build обеспечивает тесную интеграцию с исходным кодом и быстрые, безопасные сборки в нашей облачной среде. Эта настройка позволяет осуществлять быструю итерацию: разработчик может слить исправление ошибки, и оно может быть развернуто в производственной среде в течение нескольких минут без ручного вмешательства, что является значительным конкурентным преимуществом.

### **5.2. Наблюдаемость и оценка с помощью LangSmith**

#### **Обязательная интеграция**

LangSmith не является опциональным для этой архитектуры; он необходим. Трассировка будет включена по умолчанию во всех средах путем установки переменной окружения LANGCHAIN\_TRACING\_V2=true.22

#### **Отладка и оценка**

* **Отладка и трассировка:** LangSmith предоставляет бесценную визуальную трассировку каждого выполнения LangGraph. Разработчики могут видеть входы и выходы каждого узла, вызванные инструменты, задержку каждого шага и точное место сбоя. Это превращает отладку сложной распределенной системы из кошмара в управляемую задачу.9  
* **Стратегия оценки:** Мы будем использовать возможности оценки LangSmith для обеспечения и повышения качества.  
  1. Создание «золотого набора данных» юридических вопросов с проверенными экспертами ответами.  
  2. Автоматический запуск этого набора данных для новых версий агентской системы в рамках конвейера CI/CD.  
  3. Использование LLM-as-a-judge и пользовательских оценщиков в LangSmith для оценки результатов по таким метрикам, как Correctness (Правильность), Faithfulness (Соответствие источникам) и Clarity (Ясность).  
  4. Это обеспечивает количественную оценку производительности с течением времени, предотвращая регрессии и направляя улучшения.9

Систематическая стратегия оценки превращает контроль качества из субъективного ручного процесса в объективный автоматизированный. Интегрируя эти оценки в наш конвейер CI/CD, мы можем автоматически сравнивать каждое изменение с нашим «золотым набором данных». Это создает барьер качества: pull request, вызывающий значительную регрессию в наших метриках оценки, может быть автоматически помечен или даже заблокирован для слияния. Такой подход к качеству, основанный на данных, является фундаментальным для создания и поддержания надежной ИИ-системы корпоративного уровня.

### **5.3. Обеспечение безопасности межсервисного взаимодействия**

#### **Модель угроз и реализация**

* **Модель угроз:** Хотя наши агенты работают в рамках одного доверенного бэкенд-процесса, связь между фронтенд-клиентом и бэкенд-API является критической границей безопасности. Необходимо учитывать такие угрозы, как атаки типа «Агент-посередине» (AiTM), когда злоумышленник перехватывает и манипулирует коммуникацией.52  
* **Паттерн реализации: JWT для аутентификации API:**  
  1. **Аутентификация:** При входе пользователя в систему служба аутентификации выдает **JSON Web Token (JWT)**. Этот токен будет подписан цифровой подписью с использованием безопасного асимметричного алгоритма (например, RSA или ECDSA).54  
  2. **Передача:** Фронтенд-клиент будет включать этот JWT в заголовок Authorization: Bearer \<token\> каждого API-запроса к бэкенду FastAPI.55  
  3. **Верификация:** Бэкенд FastAPI будет иметь промежуточный слой (middleware), который для каждого входящего запроса будет проверять подпись JWT с помощью соответствующего открытого ключа. Он также будет проверять срок действия токена (exp) и его аудиторию (aud).54 Если токен недействителен, запрос отклоняется с ошибкой  
     401 Unauthorized.

JWT предоставляют безсостоянийный, масштабируемый и стандартизированный метод защиты API-уровня, который является основной точкой входа для внешнего взаимодействия с агентской системой. В отличие от традиционной аутентификации на основе сессий, требующей состояния на стороне сервера, JWT являются самодостаточными, что идеально подходит для нашей масштабируемой, бессерверной архитектуры.55 Подпись обеспечивает целостность утверждений (claims), таких как

user\_id и role, предотвращая их подделку.54 Это разделение задач между аутентификацией и бизнес-логикой является краеугольным камнем безопасного проектирования систем.

---

## **Раздел 6: Архитектура фронтенда: Интерактивный и прозрачный пользовательский опыт**

В этом разделе излагается план для компонентов, ориентированных на пользователя, с акцентом на создание интерфейса, который не только мощен, но и укрепляет доверие пользователя через прозрачность.

### **6.1. Создание интерактивного холста для документов**

#### **Рекомендация по технологии**

Для компонента DocumentCanvas, указанного во второй спецификации пользователя, рекомендуется использовать **Tldraw** вместо альтернатив, таких как Fabric.js.

* **Обоснование:** Tldraw — это современный, полнофункциональный SDK для создания интерактивных досок, созданный с нуля на React.57 Он предлагает превосходный опыт для разработчиков, богатый набор готовых инструментов (выделение, рисование, текст и т. д.) и высокую расширяемость для создания пользовательских фигур и инструментов.58 Его архитектура лучше соответствует современной фронтенд-разработке, чем более традиционный и низкоуровневый Fabric.js.60

#### **Архитектурный подход**

1. DocumentCanvas будет компонентом React, который оборачивает компонент \<Tldraw /\>.  
2. Когда пользователь нажимает «Открыть в редакторе» для документа, сгенерированного DocumentDrafterAgent, содержимое документа будет программно загружено на холст Tldraw с использованием API editor.createShapes.58  
3. Редактирование пользователем на холсте (перемещение текстовых блоков, редактирование текста) будет отслеживаться через систему управления состоянием Tldraw.  
4. Кнопка «Сохранить» будет запускать функцию, которая извлекает текущее состояние с холста и отправляет его на бэкенд для обновления документа.

### **6.2. Потоковая передача «мыслей» агента пользователю**

#### **Рекомендация по технологии**

Рекомендуется использовать **Server-Sent Events (SSE)** вместо WebSockets для потоковой передачи обновлений статуса агента.

* **Обоснование:** Поток информации является однонаправленным: от сервера (агента) к клиенту (пользователю). SSE — это более простой протокол, построенный на стандартном HTTP, что делает его проще в реализации, отладке и менее вероятным для блокировки корпоративными брандмауэрами.62 WebSockets более мощные, но вносят излишнюю сложность для однонаправленного потока, так как они предназначены для полнодуплексной, двунаправленной связи.64

#### **Реализация**

1. Бэкенд FastAPI будет иметь конечную точку, которая возвращает StreamingResponse с media\_type, установленным в text/event-stream.66  
2. По мере выполнения рабочего процесса LangGraph, CoordinatorAgent (или выделенный узел логирования) будет yieldить обновления статуса (например, {"status": "Executing LegalSearchAgent", "details": "Searching for precedents..."}).  
3. Фронтенд на React будет использовать нативный API EventSource для подключения к этой конечной точке и прослушивания сообщений.  
4. Компонент AgentStatus.jsx будет получать эти события и обновлять пользовательский интерфейс в режиме реального времени, показывая пользователю, о чем именно «думает» система.

Сочетание интерактивного холста и прозрачной потоковой передачи статуса является мощным паттерном пользовательского опыта (UX), который укрепляет доверие и создает ощущение контроля. Системы ИИ могут восприниматься как непрозрачные «черные ящики», что снижает доверие пользователей, особенно в такой высокорисковой области, как юриспруденция. Потоковая передача «мыслей» через SSE обеспечивает прозрачное представление процесса работы агента в реальном времени. DocumentCanvas, построенный на Tldraw, позволяет пользователю напрямую взаимодействовать с результатом работы ИИ и корректировать его, превращая пользователя из пассивного потребителя в активного соавтора. Этот дизайн UX напрямую решает проблему «черного ящика». Показывая процесс (поток SSE) и позволяя напрямую манипулировать результатом (холст Tldraw), мы позиционируем LawGPT не как непогрешимого оракула, а как мощного, прозрачного и контролируемого помощника. Такое позиционирование необходимо для принятия и успешного внедрения системы среди юристов-профессионалов.

#### **Источники**

1. How do I deploy LangChain in production for real-time applications? \- Zilliz Vector Database, дата последнего обращения: июля 3, 2025, [https://zilliz.com/ai-faq/how-do-i-deploy-langchain-in-production-for-realtime-applications](https://zilliz.com/ai-faq/how-do-i-deploy-langchain-in-production-for-realtime-applications)  
2. Building Your First Agentic Workflow with LangGraph and Gemini LLM: A Step-by-Step Guide | by Krishna Popat | Searce, дата последнего обращения: июля 3, 2025, [https://blog.searce.com/building-your-first-agentic-workflow-with-langgraph-and-gemini-llm-a-step-by-step-guide-c173c9dcdfe7](https://blog.searce.com/building-your-first-agentic-workflow-with-langgraph-and-gemini-llm-a-step-by-step-guide-c173c9dcdfe7)  
3. LangGraph \- LangChain, дата последнего обращения: июля 3, 2025, [https://www.langchain.com/langgraph](https://www.langchain.com/langgraph)  
4. LangGraph: The Future of Production-Grade AI Agent Architectures | by Vikas Kumar Singh, дата последнего обращения: июля 3, 2025, [https://medium.com/@vikaskumarsingh\_60821/langgraph-the-future-of-production-grade-ai-agent-architectures-623d68dbbfb6](https://medium.com/@vikaskumarsingh_60821/langgraph-the-future-of-production-grade-ai-agent-architectures-623d68dbbfb6)  
5. LangGraph vs AutoGen: Comparing AI Agent Frameworks \- PromptLayer, дата последнего обращения: июля 3, 2025, [https://blog.promptlayer.com/langgraph-vs-autogen/](https://blog.promptlayer.com/langgraph-vs-autogen/)  
6. Building Multi-Agent Systems with LangGraph | by Clearwater Analytics Engineering, дата последнего обращения: июля 3, 2025, [https://medium.com/cwan-engineering/building-multi-agent-systems-with-langgraph-04f90f312b8e](https://medium.com/cwan-engineering/building-multi-agent-systems-with-langgraph-04f90f312b8e)  
7. Comparing Open-Source AI Agent Frameworks \- Langfuse Blog, дата последнего обращения: июля 3, 2025, [https://langfuse.com/blog/2025-03-19-ai-agent-comparison](https://langfuse.com/blog/2025-03-19-ai-agent-comparison)  
8. Which AI Agent Framework to use? CrewAI vs LangGraph vs Autogen vs Swarm \- Medium, дата последнего обращения: июля 3, 2025, [https://medium.com/accredian/which-ai-agent-framework-to-use-crewai-vs-langgraph-vs-autogen-vs-swarm-7c97f5778fc2](https://medium.com/accredian/which-ai-agent-framework-to-use-crewai-vs-langgraph-vs-autogen-vs-swarm-7c97f5778fc2)  
9. How and when to build multi-agent systems \- LangChain Blog, дата последнего обращения: июля 3, 2025, [https://blog.langchain.com/how-and-when-to-build-multi-agent-systems/](https://blog.langchain.com/how-and-when-to-build-multi-agent-systems/)  
10. LangGraph vs LlamaIndex Showdown: Who Makes AI Agents Easier ..., дата последнего обращения: июля 3, 2025, [https://medium.com/@techwithibrahim/langgraph-vs-llamaindex-showdown-who-makes-ai-agents-easier-in-javascript-bafc57ba8ac5](https://medium.com/@techwithibrahim/langgraph-vs-llamaindex-showdown-who-makes-ai-agents-easier-in-javascript-bafc57ba8ac5)  
11. LangGraph, дата последнего обращения: июля 3, 2025, [https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)  
12. Question on LangGraph \+ FastAPI \+ Multi-Tenant app. : r/LangChain \- Reddit, дата последнего обращения: июля 3, 2025, [https://www.reddit.com/r/LangChain/comments/1ip33d5/question\_on\_langgraph\_fastapi\_multitenant\_app/](https://www.reddit.com/r/LangChain/comments/1ip33d5/question_on_langgraph_fastapi_multitenant_app/)  
13. PgVector Vs Azure AI search Vs Pinecone Vs Weaviate : r/LangChain \- Reddit, дата последнего обращения: июля 3, 2025, [https://www.reddit.com/r/LangChain/comments/1fyk42u/pgvector\_vs\_azure\_ai\_search\_vs\_pinecone\_vs/](https://www.reddit.com/r/LangChain/comments/1fyk42u/pgvector_vs_azure_ai_search_vs_pinecone_vs/)  
14. Pgvector vs. Qdrant: Open-Source Vector Database Comparison | TigerData \- TimescaleDB, дата последнего обращения: июля 3, 2025, [https://www.tigerdata.com/blog/pgvector-vs-qdrant](https://www.tigerdata.com/blog/pgvector-vs-qdrant)  
15. ScaNN for AlloyDB: The postgres vector index that works well for all sizes \- Google Cloud, дата последнего обращения: июля 3, 2025, [https://cloud.google.com/blog/products/databases/how-scann-for-alloydb-vector-search-compares-to-pgvector-hnsw](https://cloud.google.com/blog/products/databases/how-scann-for-alloydb-vector-search-compares-to-pgvector-hnsw)  
16. Supercharging vector search performance and relevance with pgvector 0.8.0 on Amazon Aurora PostgreSQL | AWS Database Blog, дата последнего обращения: июля 3, 2025, [https://aws.amazon.com/blogs/database/supercharging-vector-search-performance-and-relevance-with-pgvector-0-8-0-on-amazon-aurora-postgresql/](https://aws.amazon.com/blogs/database/supercharging-vector-search-performance-and-relevance-with-pgvector-0-8-0-on-amazon-aurora-postgresql/)  
17. What's the best Vector DB? What's new in vector db and how is one better than other? \[D\], дата последнего обращения: июля 3, 2025, [https://www.reddit.com/r/MachineLearning/comments/1ijxrqj/whats\_the\_best\_vector\_db\_whats\_new\_in\_vector\_db/](https://www.reddit.com/r/MachineLearning/comments/1ijxrqj/whats_the_best_vector_db_whats_new_in_vector_db/)  
18. 10 Best Vector Databases for AI-Powered Apps in 2025 \- Galaxy, дата последнего обращения: июля 3, 2025, [https://www.getgalaxy.io/learn/data-tools/best-vector-databases-2025](https://www.getgalaxy.io/learn/data-tools/best-vector-databases-2025)  
19. Deploying LangGraph with FastAPI: A Step-by-Step Tutorial | by Sajith K \- Medium, дата последнего обращения: июля 3, 2025, [https://medium.com/@sajith\_k/deploying-langgraph-with-fastapi-a-step-by-step-tutorial-b5b7cdc91385](https://medium.com/@sajith_k/deploying-langgraph-with-fastapi-a-step-by-step-tutorial-b5b7cdc91385)  
20. Deploying Streaming AI Agents with LangGraph, FastAPI, and Google Cloud Run \- Medium, дата последнего обращения: июля 3, 2025, [https://medium.com/@chirazchahbeni/deploying-streaming-ai-agents-with-langgraph-fastapi-and-google-cloud-run-5e32232ef1fb](https://medium.com/@chirazchahbeni/deploying-streaming-ai-agents-with-langgraph-fastapi-and-google-cloud-run-5e32232ef1fb)  
21. Unlocking the Black Box: Using LangSmith to Understand and Debug Your AI Agents, дата последнего обращения: июля 3, 2025, [https://opendatascience.com/unlocking-the-black-box-using-langsmith-to-understand-and-debug-your-ai-agents/](https://opendatascience.com/unlocking-the-black-box-using-langsmith-to-understand-and-debug-your-ai-agents/)  
22. Building a Multi-Agent AI Platform with LangGraph and LangSmith \- Medium, дата последнего обращения: июля 3, 2025, [https://medium.com/@cthecm/building-a-multi-agent-ai-platform-with-langgraph-and-langsmith-6d3e03c14b11](https://medium.com/@cthecm/building-a-multi-agent-ai-platform-with-langgraph-and-langsmith-6d3e03c14b11)  
23. Function calling with the Gemini API | Google AI for Developers, дата последнего обращения: июля 3, 2025, [https://ai.google.dev/gemini-api/docs/function-calling](https://ai.google.dev/gemini-api/docs/function-calling)  
24. Building agents with Google Gemini and open source frameworks, дата последнего обращения: июля 3, 2025, [https://developers.googleblog.com/en/building-agents-google-gemini-open-source-frameworks/](https://developers.googleblog.com/en/building-agents-google-gemini-open-source-frameworks/)  
25. LangGraph Multi-Agent Systems \- Overview, дата последнего обращения: июля 3, 2025, [https://langchain-ai.github.io/langgraph/concepts/multi\_agent/](https://langchain-ai.github.io/langgraph/concepts/multi_agent/)  
26. What is a Multiagent System? | IBM, дата последнего обращения: июля 3, 2025, [https://www.ibm.com/think/topics/multiagent-system](https://www.ibm.com/think/topics/multiagent-system)  
27. Building Your First Hierarchical Multi-Agent System \- Spheron's Blog, дата последнего обращения: июля 3, 2025, [https://blog.spheron.network/building-your-first-hierarchical-multi-agent-system](https://blog.spheron.network/building-your-first-hierarchical-multi-agent-system)  
28. AI Agent best practices from one year as AI Engineer : r/AI\_Agents \- Reddit, дата последнего обращения: июля 3, 2025, [https://www.reddit.com/r/AI\_Agents/comments/1lpj771/ai\_agent\_best\_practices\_from\_one\_year\_as\_ai/](https://www.reddit.com/r/AI_Agents/comments/1lpj771/ai_agent_best_practices_from_one_year_as_ai/)  
29. How to reduce 78%+ of LLM Cost \- AI Jason, дата последнего обращения: июля 3, 2025, [https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost](https://www.ai-jason.com/learning-ai/how-to-reduce-llm-cost)  
30. Optimizing LLM Costs with Intelligent Routing: From Basic to Advanced Techniques Using LangChain and LangGraph | by Gabriel Mendes | Apr, 2025 | Medium, дата последнего обращения: июля 3, 2025, [https://medium.com/@gabrielm3/optimizing-llm-costs-with-intelligent-routing-from-basic-to-advanced-techniques-using-langchain-8ff14efe0d6a](https://medium.com/@gabrielm3/optimizing-llm-costs-with-intelligent-routing-from-basic-to-advanced-techniques-using-langchain-8ff14efe0d6a)  
31. Building Agentic AI: Leveraging Function Calling in Gemini API | by Syeedmdtalha | Medium, дата последнего обращения: июля 3, 2025, [https://medium.com/@syeedmdtalha/building-agentic-ai-leveraging-function-calling-in-gemini-api-9650a2e2ff08](https://medium.com/@syeedmdtalha/building-agentic-ai-leveraging-function-calling-in-gemini-api-9650a2e2ff08)  
32. How to handle tool calling errors, дата последнего обращения: июля 3, 2025, [https://langchain-ai.github.io/langgraphjs/how-tos/tool-calling-errors/](https://langchain-ai.github.io/langgraphjs/how-tos/tool-calling-errors/)  
33. RunnableRetry — LangChain documentation, дата последнего обращения: июля 3, 2025, [https://python.langchain.com/api\_reference/core/runnables/langchain\_core.runnables.retry.RunnableRetry.html](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.retry.RunnableRetry.html)  
34. How to handle tool errors \- Python LangChain, дата последнего обращения: июля 3, 2025, [https://python.langchain.com/docs/how\_to/tools\_error/](https://python.langchain.com/docs/how_to/tools_error/)  
35. LangGraph Simplified: Understanding Conditional edge using Hotel Guest Check-In Process | by WS | Medium, дата последнего обращения: июля 3, 2025, [https://medium.com/@Shamimw/langgraph-simplified-understanding-conditional-edge-using-hotel-guest-check-in-process-36adfe3380a8](https://medium.com/@Shamimw/langgraph-simplified-understanding-conditional-edge-using-hotel-guest-check-in-process-36adfe3380a8)  
36. Deep Retrieval at CheckThat\! 2025: Identifying Scientific Papers from Implicit Social Media Mentions via Hybrid Retrieval and Re-Ranking \- arXiv, дата последнего обращения: июля 3, 2025, [https://arxiv.org/html/2505.23250v1](https://arxiv.org/html/2505.23250v1)  
37. Vector Search Demystified: A Guide to pgvector, IVFFlat, and HNSW \- Nocodo AI, дата последнего обращения: июля 3, 2025, [https://www.nocodo.ai/blog/vector-search-demystified-guide-to-pgvector-ivfflat-and-hnsw](https://www.nocodo.ai/blog/vector-search-demystified-guide-to-pgvector-ivfflat-and-hnsw)  
38. Faster similarity search performance with pgvector indexes | Google Cloud Blog, дата последнего обращения: июля 3, 2025, [https://cloud.google.com/blog/products/databases/faster-similarity-search-performance-with-pgvector-indexes](https://cloud.google.com/blog/products/databases/faster-similarity-search-performance-with-pgvector-indexes)  
39. MMMORRF: Multimodal Multilingual MOdularized Reciprocal Rank Fusion \- arXiv, дата последнего обращения: июля 3, 2025, [https://arxiv.org/pdf/2503.20698?](https://arxiv.org/pdf/2503.20698)  
40. Introducing reciprocal rank fusion for hybrid search \- OpenSearch, дата последнего обращения: июля 3, 2025, [https://opensearch.org/blog/introducing-reciprocal-rank-fusion-hybrid-search/](https://opensearch.org/blog/introducing-reciprocal-rank-fusion-hybrid-search/)  
41. Reciprocal Rank Fusion (RRF) explained in 4 mins — How to score ..., дата последнего обращения: июля 3, 2025, [https://medium.com/@devalshah1619/mathematical-intuition-behind-reciprocal-rank-fusion-rrf-explained-in-2-mins-002df0cc5e2a](https://medium.com/@devalshah1619/mathematical-intuition-behind-reciprocal-rank-fusion-rrf-explained-in-2-mins-002df0cc5e2a)  
42. Agentic GraphRAG for Commercial Contracts \- Graph Database & Analytics \- Neo4j, дата последнего обращения: июля 3, 2025, [https://neo4j.com/blog/developer/agentic-graphrag-for-commercial-contracts/](https://neo4j.com/blog/developer/agentic-graphrag-for-commercial-contracts/)  
43. GraphRAG: The Practical Guide for Cost-Effective Document Analysis with Knowledge Graphs \- LearnOpenCV, дата последнего обращения: июля 3, 2025, [https://learnopencv.com/graphrag-explained-knowledge-graphs-medical/](https://learnopencv.com/graphrag-explained-knowledge-graphs-medical/)  
44. Self-RAG: AI That Knows When to Double-Check \- Analytics Vidhya, дата последнего обращения: июля 3, 2025, [https://www.analyticsvidhya.com/blog/2025/01/self-rag/](https://www.analyticsvidhya.com/blog/2025/01/self-rag/)  
45. Implementing Self-Reflective RAG using LangGraph and FAISS \- Athina AI Hub, дата последнего обращения: июля 3, 2025, [https://hub.athina.ai/athina-originals/self-reflective-rag/](https://hub.athina.ai/athina-originals/self-reflective-rag/)  
46. LangGraph (Part 4): Human-in-the-Loop for Reliable AI Workflows ..., дата последнего обращения: июля 3, 2025, [https://medium.com/@sitabjapal03/langgraph-part-4-human-in-the-loop-for-reliable-ai-workflows-aa4cc175bce4](https://medium.com/@sitabjapal03/langgraph-part-4-human-in-the-loop-for-reliable-ai-workflows-aa4cc175bce4)  
47. Building Intelligent Human-in-the-Loop Workflows with LangGraph Interrupts and RAG in a Multi-Agent Architecture | by Riddhiman Sherlekar | Medium, дата последнего обращения: июля 3, 2025, [https://medium.com/@riddhimansherlekar/building-intelligent-human-in-the-loop-workflows-with-langgraph-interrupts-and-rag-in-a-multi-agent-4ed7b51fb6ff](https://medium.com/@riddhimansherlekar/building-intelligent-human-in-the-loop-workflows-with-langgraph-interrupts-and-rag-in-a-multi-agent-4ed7b51fb6ff)  
48. Deploying a FastAPI Application with CI/CD Pipeline: HNG Task 2 \- DEV Community, дата последнего обращения: июля 3, 2025, [https://dev.to/dipe\_/deploying-a-fastapi-application-with-cicd-pipeline-hng-task-3-5598](https://dev.to/dipe_/deploying-a-fastapi-application-with-cicd-pipeline-hng-task-3-5598)  
49. Simple CI/CD for Your FastAPI App with Google Cloud Build and Cloud Run \- David Muraya, дата последнего обращения: июля 3, 2025, [https://davidmuraya.com/blog/fastapi-cloud-build-run-deploy-on-gcp/](https://davidmuraya.com/blog/fastapi-cloud-build-run-deploy-on-gcp/)  
50. From Zero to Hero: Deploying a FastAPI Backend on Google Cloud Run with CI/CD, Docker & MongoDB \- DEV Community, дата последнего обращения: июля 3, 2025, [https://dev.to/surendergupta/from-zero-to-hero-deploying-a-fastapi-backend-on-google-cloud-run-with-cicd-docker-mongodb-1301](https://dev.to/surendergupta/from-zero-to-hero-deploying-a-fastapi-backend-on-google-cloud-run-with-cicd-docker-mongodb-1301)  
51. Deploy LangChain on Cloud Run with LangServe | Google Cloud Blog, дата последнего обращения: июля 3, 2025, [https://cloud.google.com/blog/products/ai-machine-learning/deploy-langchain-on-cloud-run-with-langserve](https://cloud.google.com/blog/products/ai-machine-learning/deploy-langchain-on-cloud-run-with-langserve)  
52. arXiv:2504.00218v1 \[cs.MA\] 31 Mar 2025, дата последнего обращения: июля 3, 2025, [https://www.arxiv.org/pdf/2504.00218](https://www.arxiv.org/pdf/2504.00218)  
53. Red-Teaming LLM Multi-Agent Systems via ... \- OpenReview, дата последнего обращения: июля 3, 2025, [https://openreview.net/pdf/68c110ea5e3486b070992aea263a31191b66cb24.pdf](https://openreview.net/pdf/68c110ea5e3486b070992aea263a31191b66cb24.pdf)  
54. JSON Web Token Introduction \- jwt.io, дата последнего обращения: июля 3, 2025, [https://jwt.io/introduction](https://jwt.io/introduction)  
55. JWT Authentication: A Secure & Scalable Solution for Modern ..., дата последнего обращения: июля 3, 2025, [https://www.authgear.com/post/jwt-authentication-a-secure-scalable-solution-for-modern-applications](https://www.authgear.com/post/jwt-authentication-a-secure-scalable-solution-for-modern-applications)  
56. JWT Security Best Practices | Curity, дата последнего обращения: июля 3, 2025, [https://curity.io/resources/learn/jwt-best-practices/](https://curity.io/resources/learn/jwt-best-practices/)  
57. tldraw: Build whiteboards in React with the tldraw SDK, дата последнего обращения: июля 3, 2025, [https://tldraw.dev/](https://tldraw.dev/)  
58. Shapes • tldraw Docs, дата последнего обращения: июля 3, 2025, [https://tldraw.dev/docs/shapes](https://tldraw.dev/docs/shapes)  
59. tldraw examples, дата последнего обращения: июля 3, 2025, [https://examples.tldraw.com/](https://examples.tldraw.com/)  
60. Drawing projects \- Best of JS, дата последнего обращения: июля 3, 2025, [https://bestofjs.org/projects?tags=drawing](https://bestofjs.org/projects?tags=drawing)  
61. Empowering Designers: The Impact of tldraw on Web Development \- DhiWise, дата последнего обращения: июля 3, 2025, [https://www.dhiwise.com/post/Empowering%20Designers:%20The%20Impact%20of%20tldraw%20on%20Web%20Development](https://www.dhiwise.com/post/Empowering%20Designers:%20The%20Impact%20of%20tldraw%20on%20Web%20Development)  
62. WebSockets vs Server-Sent Events: Key differences and which to use in 2024, дата последнего обращения: июля 3, 2025, [https://ably.com/blog/websockets-vs-sse](https://ably.com/blog/websockets-vs-sse)  
63. WebSockets vs. Server-Sent events/EventSource \[closed\] \- Stack Overflow, дата последнего обращения: июля 3, 2025, [https://stackoverflow.com/questions/5195452/websockets-vs-server-sent-events-eventsource](https://stackoverflow.com/questions/5195452/websockets-vs-server-sent-events-eventsource)  
64. Server Sent Events in OpenAPI best practices \- Speakeasy, дата последнего обращения: июля 3, 2025, [https://www.speakeasy.com/openapi/content/server-sent-events](https://www.speakeasy.com/openapi/content/server-sent-events)  
65. Streaming: Websockets vs SSE? : r/Rag \- Reddit, дата последнего обращения: июля 3, 2025, [https://www.reddit.com/r/Rag/comments/1f721qu/streaming\_websockets\_vs\_sse/](https://www.reddit.com/r/Rag/comments/1f721qu/streaming_websockets_vs_sse/)  
66. FastAPI StreamingResponse not streaming with generator function \- Stack Overflow, дата последнего обращения: июля 3, 2025, [https://stackoverflow.com/questions/75740652/fastapi-streamingresponse-not-streaming-with-generator-function](https://stackoverflow.com/questions/75740652/fastapi-streamingresponse-not-streaming-with-generator-function)